{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Define a function to read input data and create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "des = ['Existing PSP services and date of interaction of patient with each service',\n",
    "        'App service data', 'Demographic data of patient', 'Data of campaign targeting patients to keep them engaged',\n",
    "        'Data of patient calls with the support team to discuss, order and provide services',\n",
    "        'Specialist team providing assistance and guidance/motivation for patient engagement with services',\n",
    "        'Tracking the status of shared content with patient', 'Tracking the status of shared content with patient',\n",
    "        'Drug sponsor of patient']\n",
    "\n",
    "def read_data(inputfile):\n",
    "    \"\"\"\n",
    "    This function helps create a data dictionary.\n",
    "    Input: Workbook/spreadsheet\n",
    "    Output: Unique patients, #rows, #columns, #duplicates, #NULLs in columns in each tab/sheet\n",
    "    \"\"\"\n",
    "    \n",
    "    wb = openpyxl.load_workbook(inputfile)\n",
    "    names = wb.sheetnames\n",
    "    n1 = len(names)\n",
    "    print('Total number of sheets in the workbook = {}'.format(n1))\n",
    "    print('Sheet names respectively:', names)\n",
    "    print('')\n",
    "\n",
    "    columns = [] #columns of data dictionary\n",
    "    for i in range(1, n1):\n",
    "        df = pd.read_excel(inputfile, sheet_name = names[i])\n",
    "        n2 = len(df['patient_id'].unique())\n",
    "        n0 = len(df[df.duplicated()])\n",
    "        col_names = df.columns.tolist()\n",
    "        cols = df.columns[df.isnull().any()].tolist()\n",
    "        #n5 = len(cols)\n",
    "            \n",
    "        n3 = df.shape[0]\n",
    "        n4 = df.shape[1]\n",
    "        sheet = names[i]\n",
    "        dt = [] #datatypes of dataframe columns\n",
    "        for j in range(n4):\n",
    "            dt.append(str(df[df.columns[j]].dtype))\n",
    "                       \n",
    "        #print('Number of unique patients in sheet {} = {}'.format(i, n2))\n",
    "        #print('Number of duplicates in sheet {} = {}'.format(i, n0))\n",
    "        #print('#Columns having missing values in sheet {} = {}'.format(i, n5))\n",
    "    \n",
    "        columns.append({'Sheet': sheet, 'Description': des[i], '#Duplicates': n0, '#Unique patients': n2, '#Rows': n3, '#Columns': n4, 'Column names':col_names, 'Datatypes of columns': dt, 'Columns with NULLs': cols})\n",
    "    dict_df = pd.DataFrame(columns)\n",
    "    dict_df.to_csv('Data dictionary.csv', index = False)\n",
    "\n",
    "    return print('Dictionary created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, value in enumerate(df0.dtypes):\n",
    "#    print(value)\n",
    "inputfile = 'AbbVie_Capstone.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sheets in the workbook = 9\n",
      "Sheet names respectively: ['Interaction', 'App', 'Demog', 'Campaign', 'Support_services', 'Specialist', 'Content Access 1', 'Content Access 2', 'Payor']\n",
      "\n",
      "Dictionary created.\n",
      "CPU times: total: 2min 46s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "read_data(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994 (489212, 3)\n",
      "['Support_person' 'Collateral' 'App' 'Email' 'Moving bag' 'Med Rem'\n",
      " 'Removal kit' 'training_gadget' 'HPS_low' 'HPP-high'] 43\n"
     ]
    }
   ],
   "source": [
    "df0 = pd.read_excel(inputfile, sheet_name = 'Interaction')\n",
    "print(len(df0['patient_id'].unique()), df0.shape)\n",
    "print(df0['service'].unique(), len(df0[df0.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(inputfile, sheet_name = 'Demog')\n",
    "df3 = pd.read_excel(inputfile, sheet_name = 'Payor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2528437 entries, 0 to 2528436\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   patient_id           int64         \n",
      " 1   service              object        \n",
      " 2   date of interaction  datetime64[ns]\n",
      " 3   enrolled_channel     object        \n",
      " 4   enrolled date        datetime64[ns]\n",
      " 5   gender               object        \n",
      " 6   age                  object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(4)\n",
      "memory usage: 154.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.merge(df0, df2, how = 'outer')\n",
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2540922 entries, 0 to 2540921\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   patient_id           int64         \n",
      " 1   service              object        \n",
      " 2   date of interaction  datetime64[ns]\n",
      " 3   enrolled_channel     object        \n",
      " 4   enrolled date        datetime64[ns]\n",
      " 5   gender               object        \n",
      " 6   age                  object        \n",
      " 7   payor                object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(5)\n",
      "memory usage: 174.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_2 = pd.merge(df_1, df3, how = 'outer')\n",
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('Interaction+demography+payor.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merging 2 sheets at a time (except sheet 0 - 'Interaction') sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(inputfile, sheet_name = 'App')\n",
    "df2 = pd.read_excel(inputfile, sheet_name = 'Demog')\n",
    "df3 = pd.read_excel(inputfile, sheet_name = 'Payor')\n",
    "\n",
    "df4 = pd.read_excel(inputfile, sheet_name = 'Campaign')\n",
    "df5 = pd.read_excel(inputfile, sheet_name = 'Support_services')\n",
    "df6 = pd.read_excel(inputfile, sheet_name = 'Specialist')\n",
    "df7 = pd.read_excel(inputfile, sheet_name = 'Content Access 1')\n",
    "df8 = pd.read_excel(inputfile, sheet_name = 'Content Access 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df7.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df7.columns.tolist())\n",
    "#print(df8.columns.tolist())\n",
    "\n",
    "print(df8.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df77 = df7.drop(['last_click', 'last_open', 'total_clicks'], axis = 1) #last_click & last_open has most NULLs\n",
    "df77.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df88 = df8.drop(['total_clicks'], axis = 1) #this is in general higher than total_opens\n",
    "df88.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.merge(df1, df2, how = \"outer\") \n",
    "df123 = pd.merge(df12, df3, how = 'outer')\n",
    "len(df123['patient_id'].unique()) #App plus demog plus payor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df123.drop(['response_time'], axis = 1) #Not much info\n",
    "df11.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df45 =  pd.merge(df4, df5, how = \"outer\") \n",
    "len(df45['patient_id'].unique()) #campaign plus support services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df45.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df67 = pd.merge(df6, df77, how = \"outer\") \n",
    "df678 = pd.merge(df67, df88, how = \"outer\")\n",
    "len(df678['patient_id'].unique()) #specialist plus content access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df678.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22 = df678.drop(['document_views'], axis = 1) #Most NULLs\n",
    "df22.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff = dd.merge(df22, df11, how = 'outer')\n",
    "#dff.info(memory_usage = 'deep')\n",
    "\n",
    "df11.to_csv('App+Demography+Payor.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df11.shape[0]+df22.shape[0]+df45.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df11.memory_usage(index = False)\n",
    "df11.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df22.memory_usage(index = False)\n",
    "df22.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df45.memory_usage(index = False)\n",
    "df45.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob = 0.95\n",
    "#critical = chi2.ppf(prob, dof) #critical value\n",
    "#print('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\n",
    "#if abs(stat) >= critical:\n",
    "# print('Dependent (reject Null hypothesis)') #significant result\n",
    "#else:\n",
    "# print('Independent (accept Null hypothesis)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Med Rem -> SMS, Phone call, Notification/Alert, Email\n",
    "\n",
    "#df2.drop(df2[df2['delivery status'] == 'Left Message - Third Attempt Made; Did Not Hear From Patient'].index, \n",
    "#         inplace = True)\n",
    "#df2.drop(df2[df2['delivery status'] == 'UNDELIVERED'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['payor'] = df['payor'].replace(['Commercial', 'Government', 'manufacturer', 'Unknown', 'Others',\n",
    "       #'Commercial +', 'Government +'],[1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "#df['payor'].dtype\n",
    "\n",
    "#df['gender'] = df['gender'].replace(['M', 'F', 'UNKNOWN'],[1, 2, 3])\n",
    "\n",
    "#df['age'] = df['age'].replace(['26-40', '41-65', '65+', '18-25', '<18', 'UNKNOWN'],[1, 2, 3, 4, 5, 6])\n",
    "\n",
    "#df['service'] = df['service'].replace(['Support_person', 'Collateral', 'App', 'Email', 'Moving bag',\n",
    "       #'Med Rem', 'Removal kit', 'training_gadget', 'HPS_low', 'HPP-high'],[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nrows = 200000 \n",
    "#df1 = pd.read_csv('App_Content Access_Campaign.csv', nrows = nrows, low_memory = False)\n",
    "\n",
    "#df1['response_time'] =  pd.to_datetime(df1['response_time'], format='%H:%M:%S')\n",
    "#df1['response_hour'] = df1['response_time'].dt.hour\n",
    "\n",
    "#df1['Months on program'] = df1['Months on program'].astype(object)\n",
    "\n",
    "#dff = df1.join(df1, df2, how = 'outer', on = \"patient_id\") \n",
    "\n",
    "#dff = dd.merge(df11, df22, how = 'outer') \n",
    "\n",
    "#ads[ads.select_dtypes(['object']).columns] = ads.select_dtypes(['object']).apply(lambda x: x.astype('category'))\n",
    "\n",
    "##df.count()\n",
    "#inputFile = \"C:\\\\Users\\\\RanjaSarkar\\\\Desktop\\\\PSP\\\\Raw\\\\AbbVie_Capstone.xlsx\"\n",
    "#show(df)\n",
    "#msn.bar(df, color = 'blue')\n",
    "#len(df[df.duplicated(keep = 'first')])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 #95% probability that the Null is true\n",
    "print('significance = %.4f, p = %.4f' % (alpha, p))\n",
    "if p <= alpha:\n",
    " print('Dependent (reject Null hypothesis)') #significant result\n",
    "else:\n",
    " print('Independent (accept Null hypothesis)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['payor'] = df['payor'].fillna('Unknown')\n",
    "#df['payor'] = df['payor'].replace(['Cash','Cash/ICF'],'Others')\n",
    "\n",
    "#df1['patient_id'] = df1['patient_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "42231b65e1786e7daa5ad38de54c2b375375a5c800a17b757e94120e2e33e88e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
